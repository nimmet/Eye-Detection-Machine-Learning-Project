{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00724a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf9f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "# while True:\n",
    "#     ret,frame = cap.read()\n",
    "#     img_width = frame.shape[1]\n",
    "#     img_height = frame.shape[0]\n",
    "#     frame_blob = cv2.dnn.blobFromImage(frame,1/255,(416,416),swapRB=True,\n",
    "#                                 crop=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55fe3575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\namtu\\\\Documents\\\\ML\\\\Learn_YOLO\\\\yolo_pretrained_image'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ab442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4a286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94c5dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted object person: 99.59%.\n",
      "Predicted object person: 99.72%.\n",
      "Predicted object person: 99.57%.\n",
      "Predicted object person: 99.24%.\n",
      "Predicted object person: 99.73%.\n",
      "Predicted object person: 99.37%.\n",
      "Predicted object person: 99.25%.\n",
      "Predicted object person: 98.22%.\n",
      "Predicted object cellphone: 65.65%.\n",
      "Predicted object cellphone: 74.92%.\n",
      "Predicted object cellphone: 87.56%.\n",
      "Predicted object person: 71.19%.\n",
      "Predicted object cellphone: 75.56%.\n",
      "Predicted object person: 55.35%.\n",
      "Predicted object cellphone: 92.55%.\n",
      "Predicted object person: 58.47%.\n",
      "Predicted object cellphone: 84.29%.\n",
      "Predicted object person: 60.80%.\n",
      "Predicted object cellphone: 76.46%.\n",
      "Predicted object person: 64.58%.\n",
      "Predicted object cellphone: 87.59%.\n",
      "Predicted object person: 98.44%.\n",
      "Predicted object person: 98.73%.\n",
      "Predicted object person: 97.87%.\n"
     ]
    }
   ],
   "source": [
    "# cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "# when we want to use our webcam, we can use this code\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "    frame_blob = cv2.dnn.blobFromImage(frame,1/255,(416,416),swapRB=True,\n",
    "                                crop=False)\n",
    "# img_width = img.shape[0]\n",
    "# img_height = img.shape[1]\n",
    "# img_blob = cv2.dnn.blobFromImage(img,1/255,(416,416),swapRB=True,\n",
    "#                                 crop=False)\n",
    "\n",
    "\n",
    "    labels = [\"person\",\n",
    "              \"bicycle\",\"car\",\"motorcycle\",\"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\n",
    "                        \"trafficlight\",\"firehydrant\",\"stopsign\",\"parkingmeter\",\"bench\",\"bird\",\"cat\",\n",
    "                        \"dog\",\"horse\",\"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\"giraffe\",\"backpack\",\n",
    "                        \"umbrella\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sportsball\",\n",
    "                        \"kite\",\"baseballbat\",\"baseballglove\",\"skateboard\",\"surfboard\",\"tennisracket\",\n",
    "                        \"bottle\",\"wineglass\",\"cup\",\"fork\",\"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\n",
    "                        \"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hotdog\",\"pizza\",\"donut\",\"cake\",\"chair\",\n",
    "                        \"sofa\",\"pottedplant\",\"bed\",\"diningtable\",\"toilet\",\"tvmonitor\",\"laptop\",\"mouse\",\n",
    "                        \"remote\",\"keyboard\",\"cellphone\",\"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\n",
    "                        \"book\",\"clock\",\"vase\",\"scissors\",\"teddybear\",\"hairdrier\",\"toothbrush\"]\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "    colors = [\"0,255,255\",\"0,0,255\",\"255,0,0\",\"255,255,0\",\"0,255,0\"]\n",
    "    colors = [np.array(color.split(\",\")).astype(\"int\") for color in colors]\n",
    "    colors = np.array(colors)\n",
    "    colors = np.tile(colors,(18,1))\n",
    "    \n",
    "    model = cv2.dnn.readNetFromDarknet(r\"C:/Users/namtu/Documents/ML/Learn_YOLO/pretrained_model/yolov3.cfg\",\n",
    " r\"C:/Users/namtu/Documents/ML/Learn_YOLO/pretrained_model/yolov3.weights\")\n",
    "\n",
    "    layers = model.getLayerNames()\n",
    "    output_layer = [layers[layer-1] for layer in model.getUnconnectedOutLayers()]\n",
    "\n",
    "    model.setInput(frame_blob)\n",
    "\n",
    "    detection_layers = model.forward(output_layer)\n",
    "    \n",
    "    ids_list = []\n",
    "    boxes_list = []\n",
    "    confidences_list = []\n",
    "    \n",
    "    \n",
    "    for detection_layer in detection_layers:\n",
    "        for object_detection in detection_layer:\n",
    "            scores = object_detection[5:]\n",
    "            predicted_id = np.argmax(scores)\n",
    "            confidence = scores[predicted_id]\n",
    "\n",
    "            if confidence > 0.3:\n",
    "\n",
    "                label = labels[predicted_id]\n",
    "                bounding_box = object_detection[0:4]*np.array([frame_width,frame_height,frame_width,frame_height])\n",
    "                (box_center_x,box_center_y,box_width,box_height) = bounding_box.astype(\"int\")\n",
    "\n",
    "                start_x = int(box_center_x-(box_width/2))\n",
    "                start_y = int(box_center_y-(box_height/2))\n",
    "\n",
    "                # Non-Maximum Suppression 2\n",
    "                ids_list.append(predicted_id)\n",
    "                confidences_list.append(float(confidence))\n",
    "                boxes_list.append([start_x,start_y,\n",
    "                                  int(box_width),int(box_height)])\n",
    "    \n",
    "    \n",
    "    max_ids = cv2.dnn.NMSBoxes(boxes_list,confidences_list,0.5,0.4)\n",
    "\n",
    "    for max_id in max_ids:\n",
    "        max_class_id = max_id\n",
    "        box = boxes_list[max_class_id]\n",
    "\n",
    "        start_x = box[0]\n",
    "        start_y = box[1]\n",
    "        box_width = box[2]\n",
    "        box_height = box[3]\n",
    "\n",
    "        predicted_id = ids_list[max_class_id]\n",
    "        label = labels[predicted_id]\n",
    "        confidence = confidences_list[max_class_id]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        end_x = start_x + box_width\n",
    "        end_y = start_y + box_height\n",
    "\n",
    "        box_color = colors[predicted_id]\n",
    "        box_color = [int(each) for each in box_color]\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label,confidence*100)\n",
    "        print(\"Predicted object {}.\".format(label))\n",
    "\n",
    "        cv2.rectangle(frame,(start_x,start_y),(end_x,end_y),\n",
    "                     box_color,2)\n",
    "        cv2.putText(frame,label,(start_x,start_y-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX,0.5,box_color,2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Detection Window\",frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = cv2.dnn.readNetFromDarknet(r\"C:/Users/namtu/Documents/ML/Learn_YOLO/pretrained_model/yolov3.cfg\",\n",
    "#  r\"C:/Users/namtu/Documents/ML/Learn_YOLO/pretrained_model/yolov3.weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e15d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = model.getLayerNames()\n",
    "# output_layer = [layers[layer-1] for layer in model.getUnconnectedOutLayers()]\n",
    "\n",
    "# model.setInput(img_blob)\n",
    "\n",
    "# detection_layers = model.forward(output_layer)\n",
    "\n",
    "\n",
    "# Non-Maximum Suppression 1\n",
    "\n",
    "# ids_list = []\n",
    "# boxes_list = []\n",
    "# confidences_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce01bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for detection_layer in detection_layers:\n",
    "#     for object_detection in detection_layer:\n",
    "#         scores = object_detection[5:]\n",
    "#         predicted_id = np.argmax(scores)\n",
    "#         confidence = scores[predicted_id]\n",
    "        \n",
    "#         if confidence > 0.3:\n",
    "            \n",
    "#             label = labels[predicted_id]\n",
    "#             bounding_box = object_detection[0:4]*np.array([frame_width,frame_height,frame_width,frame_height])\n",
    "#             (box_center_x,box_center_y,box_width,box_height) = bounding_box.astype(\"int\")\n",
    "            \n",
    "#             start_x = int(box_center_x-(box_width/2))\n",
    "#             start_y = int(box_center_y-(box_height/2))\n",
    "            \n",
    "#             # Non-Maximum Suppression 2\n",
    "#             ids_list.append(predicted_id)\n",
    "#             confidences_list.append(float(confidence))\n",
    "#             boxes_list.append([start_x,start_y,\n",
    "#                               int(box_width),int(box_height)])\n",
    "            \n",
    "             # Non-Maximum Suppression 3\n",
    "                \n",
    "# max_ids = cv2.dnn.NMSBoxes(boxes_list,confidences_list,0.5,0.4)\n",
    "                \n",
    "# for max_id in max_ids:\n",
    "#     max_class_id = max_id\n",
    "#     box = boxes_list[max_class_id]\n",
    "    \n",
    "#     start_x = box[0]\n",
    "#     start_y = box[1]\n",
    "#     box_width = box[2]\n",
    "#     box_height = box[3]\n",
    "    \n",
    "#     predicted_id = ids_list[max_class_id]\n",
    "#     label = labels[predicted_id]\n",
    "#     confidence = confidences_list[max_class_id]\n",
    "    \n",
    "                \n",
    "                \n",
    "            \n",
    "#     end_x = start_x + box_width\n",
    "#     end_y = start_y + box_height\n",
    "\n",
    "#     box_color = colors[predicted_id]\n",
    "#     box_color = [int(each) for each in box_color]\n",
    "\n",
    "#     label = \"{}: {:.2f}%\".format(label,confidence*100)\n",
    "#     print(\"Predicted object {}.\".format(label))\n",
    "\n",
    "#     cv2.rectangle(img,(start_x,start_y),(end_x,end_y),\n",
    "#                  box_color,1)\n",
    "#     cv2.putText(img,label,(start_x,start_y-10),\n",
    "#                cv2.FONT_HERSHEY_SIMPLEX,0.5,box_color,1)\n",
    "# while True:          \n",
    "#     cv2.imshow(\"Detection Window\",img)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc51e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cbacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3267b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70501801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab78f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
